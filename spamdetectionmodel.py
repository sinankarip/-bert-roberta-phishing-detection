{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"jupyter\":{\"outputs_hidden\":false}}\nimport re\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom transformers import pipeline\nimport pickle\nimport warnings\nwarnings.filterwarnings('ignore') \n\nclass SpamDetectionModel:\n    def __init__(self, model_path, label_names=None, spam_threshold=0.4) :\n        \"\"\"\n        Spam Detection Model with LightGBM\n        Detects spam/phishing (0) vs safe/legitimate (1) messages\n        \n        Args:\n            model_path (str): Path to the saved LightGBM model\n            label_names (list): List of label names for classification\n        \"\"\"\n        self.model = lgb.Booster(model_file=model_path)\n        self.label_names = label_names or ['spam/phishing', 'safe/legitimate']  \n        self.spam_threshold = spam_threshold \n        \n        self._init_pipelines()\n        \n\n        self.label_map = {\n            \"LABEL_0\": \"negative\",\n            \"LABEL_1\": \"neutral\", \n            \"LABEL_2\": \"positive\"\n        }\n    \n    def _init_pipelines(self):\n        \"\"\"Initialize HuggingFace pipelines\"\"\"\n        try:\n        \n            self.sentiment_pipeline = pipeline(\n                'sentiment-analysis',\n                model='cardiffnlp/twitter-roberta-base-sentiment-latest',\n                tokenizer='cardiffnlp/twitter-roberta-base-sentiment-latest',\n                device=0,  \n                return_all_scores=True\n            )\n            \n      \n            self.feat_ext = pipeline(\n                'feature-extraction', \n                model='bert-base-uncased', \n                device=0  \n            )\n            \n        except Exception as e:\n            print(f\"Warning: GPU not available, using CPU. Error: {e}\")\n            \n            self.sentiment_pipeline = pipeline(\n                'sentiment-analysis',\n                model='cardiffnlp/twitter-roberta-base-sentiment-latest',\n                tokenizer='cardiffnlp/twitter-roberta-base-sentiment-latest',\n                device=-1,\n                return_all_scores=True\n            )\n            \n            self.feat_ext = pipeline(\n                'feature-extraction', \n                model='bert-base-uncased', \n                device=-1\n            )\n    \n    def clean_text(self, text):\n        \"\"\"\n        Clean and preprocess text\n        \n        Args:\n            text (str): Input text\n            \n        Returns:\n            str: Cleaned text\n        \"\"\"\n        if not isinstance(text, str):\n            return \"\"\n        \n\n        text = text.replace('\\n', ' ').replace('\\r', ' ').replace('\\t', ' ')\n        \n    \n        text = re.sub(r'\\s+', ' ', text)\n        \n      \n        text = re.sub(r'\\b[\\w.-]+?@\\w+?\\.\\w+?\\b', ' [EMAIL] ', text)\n        \n      \n        text = re.sub(r'https?://\\S+|www\\.\\S+', ' [URL] ', text)\n        \n\n        text = re.sub(r'\\d{5,}', ' [NUM] ', text)\n        \n\n        text = re.sub(r'([!?.]){2,}', r'\\1', text)\n        \n   \n        text = re.sub(r'[^\\w\\s\\[\\].,!?@-]', '', text)\n   \n        text = text.lower()\n   \n        text = text.strip()\n        \n        return text\n    \n    def get_sentiment_scores(self, text):\n        \"\"\"\n        Get sentiment scores for text\n        \n        Args:\n            text (str): Input text\n            \n        Returns:\n            dict: Sentiment scores {negative, neutral, positive}\n        \"\"\"\n        if not isinstance(text, str) or not text.strip():\n            return {'negative': 0.0, 'neutral': 0.0, 'positive': 0.0}\n \n        results = self.sentiment_pipeline(text[:512])[0]\n \n        scores = {}\n        for result in results:\n            sentiment_name = self.label_map.get(result['label'], result['label'])\n            scores[sentiment_name] = result['score']\n        \n        return scores\n    \n    def get_embedding(self, text):\n        \"\"\"\n        Get BERT embedding for text\n        \n        Args:\n            text (str): Input text\n            \n        Returns:\n            np.array: 768-dimensional embedding vector\n        \"\"\"\n        if not isinstance(text, str) or not text.strip():\n            return np.zeros(768)\n \n        embedding = self.feat_ext(text[:512])[0]\n\n        return np.mean(embedding, axis=0)\n    \n    def extract_features(self, text):\n        \"\"\"\n        Extract all features from text\n        \n        Args:\n            text (str): Input text\n            \n        Returns:\n            np.array: Feature vector (768 BERT + 3 sentiment = 771 dimensions)\n        \"\"\"\n\n        clean_text = self.clean_text(text)\n\n        embeddings = self.get_embedding(clean_text)\n\n        sentiment_scores = self.get_sentiment_scores(clean_text)\n\n        sentiment_feats = np.array([\n            sentiment_scores['negative'],\n            sentiment_scores['neutral'],\n            sentiment_scores['positive']\n        ])\n\n        features = np.hstack([embeddings, sentiment_feats])\n        \n        return features\n    \n    def predict(self, text):\n        \"\"\"\n        Predict class and confidence for single text\n        \n        Args:\n            text (str): Input text\n            \n        Returns:\n            dict: Prediction results with class, confidence, and all probabilities\n        \"\"\"\n\n        features = self.extract_features(text)\n\n        features = features.reshape(1, -1)\n        \n   \n        probabilities = self.model.predict(features, num_iteration=self.model.best_iteration)\n        \n\n        if probabilities.ndim == 1:\n            probabilities = probabilities.reshape(1, -1)\n        \n        probabilities = probabilities[0]  \n        \n\n        if len(probabilities) == 1:\n            \n            pos_prob = float(probabilities[0])\n            neg_prob = 1.0 - pos_prob\n            probabilities = np.array([neg_prob, pos_prob]) \n\n        spam_prob = float(probabilities[0])\n        if spam_prob > self.spam_threshold:\n            predicted_class = self.label_names[0]  # spam/phishing\n            predicted_class_idx = 0\n        else:\n            predicted_class = self.label_names[1]  # safe/legitimate\n            predicted_class_idx = 1\n        \n        confidence = float(probabilities[predicted_class_idx])\n        \n    \n        predicted_class_idx = np.argmax(probabilities)\n        predicted_class = self.label_names[predicted_class_idx]\n        \n        \n        confidence = float(probabilities[predicted_class_idx])\n        \n \n        prob_dict = {\n            self.label_names[i]: float(probabilities[i]) \n            for i in range(len(self.label_names))\n        }\n        \n        return {\n            'predicted_class': predicted_class,\n            'confidence': confidence,\n            'probabilities': prob_dict,\n            'is_spam': predicted_class_idx == 0,  \n            'is_safe': predicted_class_idx == 1,  \n            'spam_probability': float(probabilities[0]),  \n            'safe_probability': float(probabilities[1]),  \n            'raw_text': text,\n            'cleaned_text': self.clean_text(text)\n        }\n    \n    def predict_batch(self, texts):\n        \"\"\"\n        Predict classes and confidences for multiple texts\n        \n        Args:\n            texts (list): List of input texts\n            \n        Returns:\n            list: List of prediction results\n        \"\"\"\n        results = []\n        \n        for text in texts:\n            result = self.predict(text)\n            results.append(result)\n        \n        return results\n    \n    def predict_dataframe(self, df, text_column='text'):\n        \"\"\"\n        Predict for DataFrame\n        \n        Args:\n            df (pd.DataFrame): Input DataFrame\n            text_column (str): Name of text column\n            \n        Returns:\n            pd.DataFrame: DataFrame with prediction results\n        \"\"\"\n        results = []\n        \n        for text in df[text_column]:\n            result = self.predict(text)\n            results.append(result)\n        \n\n        results_df = pd.DataFrame(results)\n        \n\n        for col in df.columns:\n            if col != text_column:\n                results_df[col] = df[col].values\n        \n        return results_df\n\n# %% [code]\n","metadata":{"_uuid":"f7a4a0c9-fdbb-4729-b9ae-97123494c673","_cell_guid":"5fef8636-7505-402b-9655-a7c3f63a8b06","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}